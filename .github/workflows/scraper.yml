name: DTEK Scraper

on:
  schedule:
    - cron: '0 * * * *'  # Run every hour
  workflow_dispatch:  # Allow manual trigger

permissions:
  contents: write  # Allow pushing to repository

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          ref: data  # Checkout data branch
          fetch-depth: 0
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          pip install playwright==1.56.1 requests
          playwright install chromium --with-deps
      
      - name: Run scraper
        env:
          BROWSERLESS_TOKEN: ${{ secrets.BROWSERLESS_TOKEN }}
        run: python scraper_github_actions.py
      
      - name: Commit and push to data branch
        run: |
          git config --global user.name 'GitHub Action'
          git config --global user.email 'action@github.com'
          
          # Force add the file
          git add dtek_data.json
          
          # Debug: show what's staged
          echo "Staged changes:"
          git diff --staged --stat
          
          # Commit if there are changes
          if git diff --staged --quiet; then
            echo "No changes detected"
          else
            TODAY=$(date -u +"%Y-%m-%d")
            LAST_COMMIT_MSG=$(git log -1 --pretty=%B 2>/dev/null || echo "")
            
            if echo "$LAST_COMMIT_MSG" | grep -q "$TODAY"; then
              git commit --amend --no-edit -m "⚡ DTEK data - $TODAY"
              git push --force origin data
              echo "✓ Amended today's commit"
            else
              git commit -m "⚡ DTEK data - $TODAY"
              git push origin data
              echo "✓ Created new commit for $TODAY"
            fi
          fi